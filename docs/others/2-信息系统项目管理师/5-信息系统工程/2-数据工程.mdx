---
hide_title: true
---

## 5.2. 数据工程
数据工程是信息系统的基础工程。

数据工程的主要研究内容包括数据建模、数据标准化、数据运维、数据开发利用和数据安全等理论和技术。

### 5.2.1. 数据建模

#### 5.2.1.1. 数据模型
根据模型应用目的不同，可以将数据模型划分为三类： <Highlight>概念模型、逻辑模型和物理模型</Highlight> 。

1. 概念模型
    -  <Highlight>概念模型也称信息模型，它是按用户的观点来对数据和信息建模</Highlight> 
    - 概念模型的基本元素包括： <Highlight>实体</Highlight> （实例是具体的，而实体则是抽象的）、 <Highlight>属性</Highlight> （实体的特征称之为属性）、 <Highlight>域</Highlight> （属性的取值范围称为该属性的域）、 <Highlight>键</Highlight> （能唯一标识每个实例的一个属性或几个属性的组合称为键）、 <Highlight>关联</Highlight> （实体之间的关联包括一对一、一对多和多对多三种）
2. 逻辑模型
    - 逻辑模型是在概念模型的基础上 <Highlight>确定模型的数据结构</Highlight> ， 目前主要的数据结构有 <Highlight>层次模型、网状模型、关系模型、面向对象模型和对象关系模型</Highlight> 。其中， <Highlight>关系模型成为目前最重要的一种逻辑数据模型</Highlight> 。
    - 关系模型的基本元素包括 <Highlight>关系、关系的属性、视图</Highlight> 等。关系模型是在概念模型的基础上构建的
    - 关系的完整性约束包括三大类型： <Highlight>实体完整性、参照完整性和用户定义的完整性</Highlight> 。其中，实体完整性、参照完整性是关系模型必须满足的完整性约束条件，
3. 物理模型
    - 物理数据模型是在逻辑数据模型的基础上，考虑各种具体的技术实现因素， <Highlight>进行数据库体系结构设计，真正实现数据在数据库中的存放</Highlight> 。
    - 物理数据模型的目标是如何 <Highlight>用数据库模式来实现逻辑数据模型，以及真正地保存数据</Highlight> 。
    - 物理模型的基本元素包括 <Highlight>表、字段、视图、索引、存储过程、触发器</Highlight> 等，其中表、字段和视图等元素与逻辑模型中基本元素有一定的对应关系。

#### 5.2.1.2. 数据建模过程
数据建模过程包括 <Highlight>数据需求分析、概念模型设计、逻辑模型设计和物理模型设计</Highlight> 等过程。

1. 数据需求分析
    - 数据需求分析就是分析用户对数据的需要和要求。 <Highlight>数据需求分析是数据建模的起点</Highlight> 
    - 数据需求分析采用 <Highlight>数据流图</Highlight> 作为工具，描述系统中数据的流动和变化， <Highlight>强调数据流和处理过程</Highlight> 。
2. 概念模型设计
    - 将需求分析得到结果抽象为概念模型的过程就是概念模型设计， <Highlight>其任务是确定实体和数据及其关联</Highlight> 。
3. 逻辑模型设计
    - 逻辑模型设计的任务就是 <Highlight>将概念模型中实体、属性和关联转换为关系模型结构中的关系模式</Highlight> 。
4. 物理模型设计
    -  <Highlight>将数据模型转换为真正的数据库结构</Highlight> 
    - 物理模型考虑的主要问题包括 <Highlight>命名、确定字段类型和编写必要的存储过程与触发器</Highlight> 等。

### 5.2.2. 数据标准化
 <Highlight>数据标准化是实现数据共享的基础</Highlight> ，为信息在异构系统之间实现语义互操作提供基础支撑。

数据标准化的主要内容包括 <Highlight>元数据标准化、数据元标准化、数据模式标准化、数据分类与编码标准化和数据标准化管理</Highlight> 。

#### 5.2.2.1. 元数据标准化
 <Highlight>元数据是关于数据的数据</Highlight> (Data About Data)。在信息界，元数据被定义为提供关于信息资源或数据的一种结构化数据，是对信息资源的结构化描述。其实质是用于描述信息资源或数据的内容、覆盖范围、质量、管理方式、数据的所有者、数据的提供方式等有关的信息。
 
 元数据体系与元数据类型：
<img src={require("./_images/Snipaste_2023-07-25_17-00-06.png").default}  />

#### 5.2.2.2. 数据元标准化
互连、互通、互操作的开放系统互连环境 （Open Systems Interconnection Environment, OSIE）。OSIE四个基本要素（ <Highlight>硬件、软件、通信和数据</Highlight> ）中的三个要素（硬件、软件和通信）

1. 数据元
    -  <Highlight>数据元是数据库、文件和数据交换的基本数据单元</Highlight> 。
    - 数据库或文件由记录或元组等组成，而记录或元组则由数据元组成。
    -  <Highlight>数据元是在数据库或文件之间进行数据交换时的基本组成</Highlight> 。
    - 在特定的语义环境中被认为是不可再分的最小数据单元。
    - 数据元一般来说由三部分组成：
        - ① 对象。对象类在面向对象的模型中与类相对应，在实体关系模型中与实体对应，如学员、教员、军事院校等。
        - ② 特性。特性对应于面向对象模型或实体-关系模型中的属性，如身高、体重、血压、脉搏、血型等。
        - ③表示。
2. 数据元提取
    - 目前常用的数据元提取方法有两种： <Highlight>自上而下（Top-Down）提取法和自下而上（Down-Top）提取法</Highlight> 。
    - 对于新建系统的数据元提取，一般适用“自上而下”的提取法。
    - 自下而上提取法也称逆向工程,对于已建系统的数据元提取，一般适用这种自下而上提取法。

<img src={require("./_images/Snipaste_2023-07-25_17-08-30.png").default}  />
<img src={require("./_images/Snipaste_2023-07-25_17-08-47.png").default}  />

#### 5.2.2.3. 数据模式标准化
 <Highlight>数据模式是数据的概念、组成、结构和相互关系的总称。</Highlight> 

是从数据的逻辑层面对数据集的内容、组成及其结构信息，进行合理的、规范的 、本质上的说明和描述。

数据模式的描述方式主要有 <Highlight>图描述方法和数据字典方法</Highlight> 。图描述方法常用的有 <Highlight>IDEFIX方法和UML图</Highlight> ，主要用来 <Highlight>描述数据集中的实体和实体之间的相互关系；数据字典形式用来描述模型中的数据集、单个实体、属性的摘要信息</Highlight> 。

#### 5.2.2.4. 数据分类与编码标准化
数据分类是根据内容的属性或特征，将数据按一定的原则和方法进行区分和归类，并建立起一定的分类体系和排列顺序。

数据分类有 <Highlight>分类对象和分类依据</Highlight> 两个要素。

数据编码是将事物或概念（编码对象）赋予具有一定规律和易于计算机、人识别处理的符号 ，形成代码元素集合。

所谓数据分类与编码标准化就是把数据分类与编码工作纳入标准化工作的领域，

 <Highlight>数据分类与编码标准化是简化信息交换、实现信息处理和信息资源共享的重要前提</Highlight> ，是建立各种信息管理系统的重要技术基础和信息保障依据

#### 5.2.2.5. 数据标准化管理
数据标准化阶段的具体过程包括 <Highlight>确定数据需求、制定数据标准、批准数据标准和实施数据标准</Highlight> 四个阶段。

1.  <Highlight>确定数据需求</Highlight> 。本阶段将 <Highlight>产生数据需求及相关的元数据、域值等</Highlight> 文件。在确定数据需求时应考虑现行的法规、政策，以及现行的数据标准。
2.  <Highlight>制定数据标准</Highlight> 。本阶段要处理“确定数据需求”阶段提出的数据需求。如果现有的数据标准不能满足该数据需求，可以建议制定新的数据标准，也可建议修改或者封存已有数据标准。推荐的、新的或修改的数据标准记录于数据字典中。这个阶段将产生供审查和批准的成套建议。
3.  <Highlight>批准数据标准</Highlight> 。本阶段的数据管理机构对提交的数据标准建议、现行数据标准的修改或封存建议进行审查。一经批准，该数据标准将扩充或修改数据模型。
4.  <Highlight>实施数据标准</Highlight> 。本阶段涉及在各信息系统中实施和改进已批准的数据标准。

### 5.2.3. 数据运维
数据质量管理是在数据产品的生产过程中，确定质量方针、目标和职责，并通过质量策划、质量控制、质量保证和质量改进，来实现所有管理职能的全部活动。

#### 5.2.3.1. 数据存储
根据不同的应用环境，通过采取合理、安全、有效的方式将数据保存到物理介质上，并能保证对数据实施有效的访问。

1. 数据存储介质。数据存储首先要解决的是存储介质的问题。存储介质是数据存储的载体 ，是数据存储的基础。 <Highlight>存储介质的类型主要有磁带、光盘和磁盘三种</Highlight> 。
2. 存储管理。存储管理的主要内容： <Highlight>资源调度管理、存储资源管理、负载均衡管理、安全管理</Highlight> 

<img src={require("./_images/Snipaste_2023-07-25_17-22-08.png").default}  />

#### 5.2.3.2. 数据备份
数据备份是为了防止由于用户操作失误、系统故障等意外原因导致的数据丢失，而将整个应用系统的数据或一部分关键数据复制到其他存储介质上的过程。

当前最常见的数据备份结构可以分为四种： <Highlight>DAS备份结构、基于LAN的备份结构、LANFREE备份结构和SERVER-FREE备份结构</Highlight> 。

常见的备份策略主要有三种： <Highlight>完全备份、差分备份和增量备份</Highlight> 。

#### 5.2.3.3. 数据容灾
根据容灾系统保护对象的不同，容灾系统分为 <Highlight>应用容灾和数据容灾</Highlight> 两类。应用容灾用于克服灾难对系统的影响，保证应用服务的完整、可靠和安全等一系列要求，使得用户在任何情况下都能得到正常的服务；数据容灾则关注于保证用户数据的高可用性，在灾难发生时能够保证应用系统中的数据尽量少丢失或不丢失，使得应用系统能不间断地运行或尽快地恢复正常运行。

 <Highlight>数据备份是数据容灾的基础。容灾不是简单备份。</Highlight> 

衡量容灾系统有 <Highlight>两个主要指标：RPO</Highlight> (Recovery Point Object)和  <Highlight>RTO</Highlight>  (Recovery Time Object), 其中 RPO 代表了当灾难发生时允许丢失的数据量；而 RTO则代表了系统恢复的时间。

#### 5.2.3.4. 数据质量评价与控制
数据质量高低必须从用户使用的角度来看，即使准确性相当高的数据，如果时效性差或者不为用户所关心，仍达不到质量管理标准。数据质量是一个广义的概念，是数据产品满足指标、状态和要求能力的特征总和。
1. 数据质量描述
    - 数据质量可以通过数据质量元素来描述， <Highlight>数据质量元素分为数据质量定量元素和数据质量非定量元素</Highlight> 。
2. 数据质量评价过程
3. 数据质量评价方法： <Highlight>直接评价法、间接评价法</Highlight> 
4. 数据质量控制
    - 数据产品的质量控制分成前期控制和后期控制两个大部分。
    -  <Highlight>前期控制包括数据录入前的质量控制、数据录入过程中的实时质量控制；后期控制为数据录入完成后的后处理质量控制与评价。</Highlight> 
    - 依据建库流程可分为： <Highlight>前期控制、过程控制、系统检测、精度评价</Highlight> 
5. 数据清理
    - 数据清理也称数据清洗。从广义上讲，是将数据库精简以除去重复记录，并使剩余部分转换成符合标准的过程。而狭义上的数据清理是特指在构建数据仓库和实现数据挖掘前对数据源进行处理，使数据实现准确性、完整性、一致性、唯一性、适时性、有效性以适应后续操作的过程。从提高数据质量的角度出发，凡是有助于提高数据质量的处理过程，都可以认为是数据清理。
    - 一般说来，数据清理主要包括 <Highlight>数据分析、数据检测和数据修正</Highlight> 三个步骤，
    - <Highlight> 数据分析</Highlight> ：是指从数据中发现 <Highlight>控制数据的一般规则</Highlight> ，比如字段域、业务规则等，通过对数据的分析，定义出数据清理的规则，并选择合适的清理算法。
    -  <Highlight>数据检测</Highlight> ：是指根据预定义的清理规则及相关数据清理算法， <Highlight>检测数据是否正确</Highlight> ，比如是否满足字段域、业务规则等，或检测记录是否重复。
    -  <Highlight>数据修正</Highlight> ：是指 <Highlight>手工或自动地修正检测到的错误数据或重复的记录</Highlight> 。

### 5.2.4. 数据开发利用

#### 5.2.4.1. 数据集成
数据集成就是将驻留在不同数据源中的数据进行整合， <Highlight>向用户提供统一的数据视图</Highlight> （一般称为全局模式），使得用户能以透明的方式访问数据。

<img src={require("./_images/Snipaste_2023-07-25_18-04-16.png").default}  />

#### 5.2.4.2. 数据挖掘
指从大量数据中提取或“挖掘”知识

<Highlight>数据挖掘与传统数据分析不同</Highlight>：  

① 两者分析对象的 <Highlight>数据量有差异</Highlight> ，数据挖掘所需的数据量比传统数据分析所需的数据量大， <Highlight>数据量越大，数据挖掘的效果越好</Highlight> ；  
② 两者运用的 <Highlight>分析方法有差异</Highlight> ， <Highlight>传统数据分析主要运用统计学的方法</Highlight> 、手段对数据进行分析，而 <Highlight>数据挖掘综合运用数据统计、人工智能、可视化等技术</Highlight> 对数据进行分析；  
③ 两者分析 <Highlight>侧重有差异</Highlight> ， <Highlight>传统数据分析通常是回顾型和验证型的</Highlight> ，通常分析已经发生了什么，而 <Highlight>数据挖掘通常是预测型和发现型的</Highlight> ，预测未来的情况，解释发生的原因；  
④ 两者 <Highlight>成熟度不同</Highlight> ， <Highlight>传统数据分析</Highlight> 由于研究较早，其分析 <Highlight>方法相当成熟</Highlight> ，而数据挖掘除基于统计学等方法外，部分方法仍处于发展阶段。

数据挖掘的目标是 <Highlight>发现隐藏于数据之后的规律或数据间的关系，从而服务于决策</Highlight> 。

数据挖掘常见的主要任务包括 <Highlight>数据总结、关联分析、分类和预测、聚类分析和孤立点分析</Highlight> 。

数据挖掘流程一般包括 <Highlight>确定分析对象、数据准备、数据挖掘、结果评估与结果应用</Highlight> 五个阶段，专业人员主要包括业务分析人员、数据挖掘人员和数据管理人员。

<img src={require("./_images/Snipaste_2023-07-25_18-05-08.png").default}  />

#### 5.2.4.3. 数据服务
数据服务主要包括 <Highlight>数据目录服务、数据查询与浏览及下载服务、数据分发服务</Highlight> 。

1. 数据目录服务
    - 数据目录服务就是要解决这些问题，是用来快捷地发现和定位所需数据资源的一种检索服务， <Highlight>是实现数据共享的重要基础功能服务之一</Highlight> 。
2. 数据查询与浏览及下载服务。
    - 数据查询、浏览和下载是 <Highlight>网上数据共享服务的重要方式</Highlight> ，
    - 用户使用数据的方式有 <Highlight>查询数据和下载数据</Highlight> 两种。
3. 数据分发服务
    - 数据分发是指数据的生产者通过各种方式将数据传送到用户的过程
    - 分发服务的核心内容包括 <Highlight>数据发布、数据发现、数据评价和数据获取</Highlight> 。

#### 5.2.4.4. 数据可视化
可视化技术是指将抽象的事物或过程变成图形图像的表示方法。

将科学与工程计算等产生的大规模数据转换为图形、图像，以直观的形式表示出来。

主要可分为七类: <Highlight>一维数据可视化、二维数据可视化、三维数据可视化、多维数据可视化、时态数据可视化、层次数据可视化和网络数据可视化</Highlight> 

<img src={require("./_images/Snipaste_2023-07-25_18-16-30.png").default}  />
<img src={require("./_images/Snipaste_2023-07-25_18-17-00.png").default}  />

#### 5.2.4.5. 信息检索
信息检索的主要方法如下：
1.  <Highlight>全文检索</Highlight> 。以文本数据为主要处理对象，根据数据资料的内容而不是外在特征来实现的信息检索手段。
2.  <Highlight>字段检索</Highlight> 。把检索对象按一定标准在不同字段中进行著录，并把不同字段作为检索依据。
3.  <Highlight>基于内容的多媒体检索</Highlight> 。按检索内容可分为图像检索、视频检索和声音检索等。
4.  <Highlight>数据挖掘</Highlight> 。从大量的、不完全的、模糊的、随机的数据中，提取隐含在其中且人们事先不知道的潜在、有用的信息和知识的过程。

信息检索的常用技术包括 <Highlight>布尔逻辑检索技术、截词检索技术、临近检索技术、限定字段检索技术、限制检索技术</Highlight> 等。
1. 布尔逻辑检索技术。严格意义上的布尔检索法是指利用布尔逻辑运算符连接各个检索词，然后由计算机进行相应的逻辑运算，以找出所需信息的方法。
2. 截词检索技术。截词检索技术是指用截断的词的一个局部进行检索，并认为凡是满足这个词局部的所有字符的信息，都为命中的信息。截词符用“？”或 “ * ”表 示 （不同系统、不同数据库，其代表的含义有所不同）。
3. 临近检索技术。临近检索又称位置检索，主要是通过检索式中的专门符号来规定检索词在结果中的相对位置。在某些情况下，若不限制检索词之间的位置关系则会造成误检，影响查准率。
4. 限定字段检索技术。限定字段检索即指定检索词在记录中出现的字段。检索时，计算机只对限定字段进行匹配运算，以提高检索效率和查准率。
5. 限制检索技术。限制检索是通过限制检索范围，达到优化检索的方法。限制检索的方式有很多种，例如进行字段检索，使用限制符，采用限制检索命令等。

### 5.2.5. 数据库安全
数据库安全是指保护数据库，防止不合法的使用所造成的数据泄露、更改或破坏。

#### 5.2.5.1. 数据库安全威胁

<img src={require("./_images/Snipaste_2023-07-25_18-21-35.png").default}  />

#### 5.2.5.2. 数据库安全对策

<img src={require("./_images/Snipaste_2023-07-25_18-22-50.png").default}  />
<img src={require("./_images/Snipaste_2023-07-25_18-23-25.png").default}  />
<img src={require("./_images/Snipaste_2023-07-25_18-23-52.png").default}  />

#### 5.2.5.3. 数据库安全机制
数据库安全机制包括 <Highlight>用户的身份认证、存取控制、数据库加密、数据审计、推理控制</Highlight> 等内容。
